{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4323945c",
   "metadata": {},
   "source": [
    "# Midterm Project – Classification Analysis (Diabetes)\n",
    "\n",
    "**Author:** Beth Spornitz  \n",
    "**Date:** November 3, 2025\n",
    "\n",
    "### Introduction\n",
    "This project predicts the likelihood of diabetes using the Pima Indians Diabetes dataset. The target is `Outcome` (1 = diabetes, 0 = no diabetes). We follow the same framework as Project 3 (Decision Tree, SVM, NN), adapted to this dataset. We load, inspect, clean, engineer features (as needed), train models, evaluate them with standard classification metrics, visualize confusion matrices and decision boundaries, and reflect after each section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ded357",
   "metadata": {},
   "source": [
    "# Core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51223b",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data\n",
    "\n",
    "**Goal:** Load the dataset and confirm structure, types, and basic stats.\n",
    "\n",
    "We’ll load from a local `data/diabetes.csv` (as required by the midterm), display the first 10 rows, check missing values, and show summary statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Diabetes dataset\n",
    "# Place diabetes.csv at: ./data/diabetes.csv\n",
    "# If needed, you can also use a known public mirror URL, but for the midterm keep a local copy in /data.\n",
    "DATA_PATH = \"data/diabetes.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Standard inspect\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head(10))\n",
    "display(df.info())\n",
    "display(df.describe(include=\"all\").T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a7699",
   "metadata": {},
   "source": [
    "**Reflection 1:**  \n",
    "What do you notice about the dataset? Are there any data issues?\n",
    "- Notes:\n",
    "  - Confirm column names and types.\n",
    "  - Look for suspicious zeros in physiological fields (e.g., BloodPressure = 0).\n",
    "  - Consider whether any columns need imputation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce9024c",
   "metadata": {},
   "source": [
    "## Section 2. Data Exploration and Preparation\n",
    "\n",
    "**Goal:** Explore distributions, check class balance, handle missing/invalid values, and prepare features for modeling.\n",
    "\n",
    "We'll:\n",
    "- Plot histograms/boxplots to see distributions and outliers.\n",
    "- Check class balance of the target (`Outcome`).\n",
    "- Handle invalid zero entries in certain medical measurements (common in this dataset), imputing with medians as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List columns\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Histograms for numeric columns\n",
    "df.hist(figsize=(12, 10), bins=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for quick outlier scan\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=df, orient=\"h\")\n",
    "plt.title(\"Boxplots of Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Target balance\n",
    "print(\"Target balance (Outcome):\")\n",
    "display(df['Outcome'].value_counts())\n",
    "df['Outcome'].value_counts(normalize=True).plot(kind='bar', title='Class Distribution (Outcome)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the Pima dataset, zeros in these columns are biologically implausible and represent missing values.\n",
    "cols_with_invalid_zero = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "\n",
    "# Count invalid zeros before\n",
    "zero_counts_before = (df[cols_with_invalid_zero] == 0).sum()\n",
    "print(\"Invalid zero counts BEFORE:\", zero_counts_before.to_dict())\n",
    "\n",
    "# Replace zeros with NaN for listed columns\n",
    "df[cols_with_invalid_zero] = df[cols_with_invalid_zero].replace(0, np.nan)\n",
    "\n",
    "# Impute NaN with median per column\n",
    "for c in cols_with_invalid_zero:\n",
    "    df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "# Verify after\n",
    "zero_counts_after = (df[cols_with_invalid_zero] == 0).sum()\n",
    "print(\"Invalid zero counts AFTER (should be 0 now):\", zero_counts_after.to_dict())\n",
    "\n",
    "# Confirm no NaNs remain\n",
    "print(\"Any NaNs left?\", df.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a13b2",
   "metadata": {},
   "source": [
    "**Reflection 2:**  \n",
    "What patterns or anomalies did you see? Which preprocessing steps were necessary?\n",
    "- Notes:\n",
    "  - Comment on distributions (e.g., Glucose/BMI).\n",
    "  - Note class balance for `Outcome`.\n",
    "  - Document the zero→NaN→median imputation choice.\n",
    "  - Mention any additional prep you considered (scaling, transforms) and why you did/didn’t apply them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0092a55b",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "\n",
    "We’ll follow the same “three cases” pattern as Project 3 to keep comparability:\n",
    "\n",
    "- **Case 1:** Single feature → `BMI`  \n",
    "- **Case 2:** Single feature → `Glucose`  \n",
    "- **Case 3:** Two features → `Glucose` + `BMI`  \n",
    "\n",
    "**Target:** `Outcome` (0 = no diabetes, 1 = diabetes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f2fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1: Feature = BMI\n",
    "X1 = df[['BMI']].dropna()\n",
    "y1 = df.loc[X1.index, 'Outcome']\n",
    "\n",
    "# Case 2: Feature = Glucose\n",
    "X2 = df[['Glucose']].dropna()\n",
    "y2 = df.loc[X2.index, 'Outcome']\n",
    "\n",
    "# Case 3: Features = Glucose + BMI\n",
    "X3 = df[['Glucose', 'BMI']].dropna()\n",
    "y3 = df.loc[X3.index, 'Outcome']\n",
    "\n",
    "# Sanity checks\n",
    "print(\"Case 1 shape:\", X1.shape, y1.shape)\n",
    "print(\"Case 2 shape:\", X2.shape, y2.shape)\n",
    "print(\"Case 3 shape:\", X3.shape, y3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d434f9",
   "metadata": {},
   "source": [
    "**Reflection 3:**  \n",
    "Why did you choose these features? How might `Glucose` and `BMI` impact predictions or accuracy? Are there others you would add in a future iteration?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae9ac3",
   "metadata": {},
   "source": [
    "## Section 4. Train a Model (Decision Tree)\n",
    "\n",
    "We’ll mirror the Project 3 workflow:\n",
    "- Split each case with **StratifiedShuffleSplit** (80/20) to preserve class proportions.\n",
    "- Train a **Decision Tree** for each case.\n",
    "- Evaluate with **classification_report** on train and test splits.\n",
    "- Plot **confusion matrices** (heatmaps).\n",
    "- Plot the **decision tree** for each case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c510b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1: BMI\n",
    "splitter1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "for train_idx1, test_idx1 in splitter1.split(X1, y1):\n",
    "    X1_train = X1.iloc[train_idx1]\n",
    "    X1_test  = X1.iloc[test_idx1]\n",
    "    y1_train = y1.iloc[train_idx1]\n",
    "    y1_test  = y1.iloc[test_idx1]\n",
    "print('Case 1 - BMI | Train:', len(X1_train), '| Test:', len(X1_test))\n",
    "\n",
    "# Case 2: Glucose\n",
    "splitter2 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "for train_idx2, test_idx2 in splitter2.split(X2, y2):\n",
    "    X2_train = X2.iloc[train_idx2]\n",
    "    X2_test  = X2.iloc[test_idx2]\n",
    "    y2_train = y2.iloc[train_idx2]\n",
    "    y2_test  = y2.iloc[test_idx2]\n",
    "print('Case 2 - Glucose | Train:', len(X2_train), '| Test:', len(X2_test))\n",
    "\n",
    "# Case 3: Glucose + BMI\n",
    "splitter3 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "for train_idx3, test_idx3 in splitter3.split(X3, y3):\n",
    "    X3_train = X3.iloc[train_idx3]\n",
    "    X3_test  = X3.iloc[test_idx3]\n",
    "    y3_train = y3.iloc[train_idx3]\n",
    "    y3_test  = y3.iloc[test_idx3]\n",
    "print('Case 3 - Glucose + BMI | Train:', len(X3_train), '| Test:', len(X3_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees (same style as Project 3)\n",
    "tree_model1 = DecisionTreeClassifier()\n",
    "tree_model1.fit(X1_train, y1_train)\n",
    "\n",
    "tree_model2 = DecisionTreeClassifier()\n",
    "tree_model2.fit(X2_train, y2_train)\n",
    "\n",
    "tree_model3 = DecisionTreeClassifier()\n",
    "tree_model3.fit(X3_train, y3_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8448a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1\n",
    "print(\"Decision Tree — Case 1 (BMI) — TRAIN\")\n",
    "print(classification_report(y1_train, tree_model1.predict(X1_train)))\n",
    "print(\"Decision Tree — Case 1 (BMI) — TEST\")\n",
    "y1_test_pred = tree_model1.predict(X1_test)\n",
    "print(classification_report(y1_test, y1_test_pred))\n",
    "\n",
    "# Case 2\n",
    "print(\"Decision Tree — Case 2 (Glucose) — TRAIN\")\n",
    "print(classification_report(y2_train, tree_model2.predict(X2_train)))\n",
    "print(\"Decision Tree — Case 2 (Glucose) — TEST\")\n",
    "y2_test_pred = tree_model2.predict(X2_test)\n",
    "print(classification_report(y2_test, y2_test_pred))\n",
    "\n",
    "# Case 3\n",
    "print(\"Decision Tree — Case 3 (Glucose + BMI) — TRAIN\")\n",
    "print(classification_report(y3_train, tree_model3.predict(X3_train)))\n",
    "print(\"Decision Tree — Case 3 (Glucose + BMI) — TEST\")\n",
    "y3_test_pred = tree_model3.predict(X3_test)\n",
    "print(classification_report(y3_test, y3_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b42021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1\n",
    "cm1 = confusion_matrix(y1_test, y1_test_pred)\n",
    "sns.heatmap(cm1, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title('Confusion Matrix — Case 1: BMI')\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Case 2\n",
    "cm2 = confusion_matrix(y2_test, y2_test_pred)\n",
    "sns.heatmap(cm2, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title('Confusion Matrix — Case 2: Glucose')\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Case 3\n",
    "cm3 = confusion_matrix(y3_test, y3_test_pred)\n",
    "sns.heatmap(cm3, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title('Confusion Matrix — Case 3: Glucose + BMI')\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d99716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plot_tree(tree_model1, feature_names=X1.columns, class_names=['No Diabetes','Diabetes'], filled=True)\n",
    "plt.title(\"Decision Tree — Case 1: BMI\")\n",
    "plt.show()\n",
    "fig.savefig(\"tree_case1_bmi.png\")\n",
    "\n",
    "# Case 2\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plot_tree(tree_model2, feature_names=X2.columns, class_names=['No Diabetes','Diabetes'], filled=True)\n",
    "plt.title(\"Decision Tree — Case 2: Glucose\")\n",
    "plt.show()\n",
    "fig.savefig(\"tree_case2_glucose.png\")\n",
    "\n",
    "# Case 3\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "plot_tree(tree_model3, feature_names=X3.columns, class_names=['No Diabetes','Diabetes'], filled=True)\n",
    "plt.title(\"Decision Tree — Case 3: Glucose + BMI\")\n",
    "plt.show()\n",
    "fig.savefig(\"tree_case3_glucose_bmi.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78204cde",
   "metadata": {},
   "source": [
    "**Reflection 4:**  \n",
    "How well did the Decision Trees perform across the three cases? Any overfitting signs (big train vs test gap)? Which inputs worked better and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a6e23",
   "metadata": {},
   "source": [
    "## Section 5. Improve the Model or Try Alternates (Implement a Second Option)\n",
    "\n",
    "We will mirror Project 3 and try:\n",
    "- **Support Vector Classifier (SVC)** for all three cases\n",
    "- **Neural Network (MLPClassifier)** for **Case 3** (two inputs)  \n",
    "We’ll evaluate with the same metrics and visualize support vectors (like Project 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017482c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC — default RBF kernel, consistent with Project 3 examples\n",
    "\n",
    "# Case 1: BMI\n",
    "svc_model1 = SVC()\n",
    "svc_model1.fit(X1_train, y1_train)\n",
    "y1_svc_pred = svc_model1.predict(X1_test)\n",
    "print(\"SVC — Case 1 (BMI) — TEST\")\n",
    "print(classification_report(y1_test, y1_svc_pred))\n",
    "\n",
    "# Case 2: Glucose\n",
    "svc_model2 = SVC()\n",
    "svc_model2.fit(X2_train, y2_train)\n",
    "y2_svc_pred = svc_model2.predict(X2_test)\n",
    "print(\"SVC — Case 2 (Glucose) — TEST\")\n",
    "print(classification_report(y2_test, y2_svc_pred))\n",
    "\n",
    "# Case 3: Glucose + BMI\n",
    "svc_model3 = SVC()\n",
    "svc_model3.fit(X3_train, y3_train)\n",
    "y3_svc_pred = svc_model3.predict(X3_test)\n",
    "print(\"SVC — Case 3 (Glucose + BMI) — TEST\")\n",
    "print(classification_report(y3_test, y3_svc_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79746a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize support vectors for Case 1 (1D BMI) — using 0.5 Y trick exactly like Project 3\n",
    "\n",
    "# Create groups based on Outcome\n",
    "diab_bmi = X1_test.loc[y1_test == 1, 'BMI']\n",
    "nod_bmi  = X1_test.loc[y1_test == 0, 'BMI']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(diab_bmi, y1_test.loc[y1_test == 1], c='yellow', marker='s', label='Diabetes (1)')\n",
    "plt.scatter(nod_bmi,  y1_test.loc[y1_test == 0], c='cyan',   marker='^', label='No Diabetes (0)')\n",
    "\n",
    "if hasattr(svc_model1, 'support_vectors_'):\n",
    "    support_x = svc_model1.support_vectors_[:, 0]\n",
    "    plt.scatter(support_x, [0.5] * len(support_x), c='black', marker='+', s=100, label='Support Vectors')\n",
    "\n",
    "plt.xlabel('BMI'); plt.ylabel('Outcome (0/1)')\n",
    "plt.title('Support Vectors — SVC (Case 1: BMI)')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize support vectors for Case 3 (Glucose, BMI)\n",
    "\n",
    "diab = X3_test[y3_test == 1]\n",
    "nod  = X3_test[y3_test == 0]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(diab['Glucose'], diab['BMI'], c='yellow', marker='s', label='Diabetes (1)')\n",
    "plt.scatter(nod['Glucose'],  nod['BMI'],  c='cyan',   marker='^', label='No Diabetes (0)')\n",
    "\n",
    "if hasattr(svc_model3, 'support_vectors_'):\n",
    "    sv = svc_model3.support_vectors_\n",
    "    plt.scatter(sv[:, 0], sv[:, 1], c='black', marker='+', s=100, label='Support Vectors')\n",
    "\n",
    "plt.xlabel('Glucose'); plt.ylabel('BMI')\n",
    "plt.title('Support Vectors — SVC (Case 3: Glucose + BMI)')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network (MLP) — Case 3 (two inputs), consistent with Project 3 style\n",
    "nn_model3 = MLPClassifier(\n",
    "    hidden_layer_sizes=(50, 25, 10),\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "nn_model3.fit(X3_train, y3_train)\n",
    "\n",
    "y3_nn_pred = nn_model3.predict(X3_test)\n",
    "print(\"Neural Network — Case 3 (Glucose + BMI) — TEST\")\n",
    "print(classification_report(y3_test, y3_nn_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_nn3 = confusion_matrix(y3_test, y3_nn_pred)\n",
    "sns.heatmap(cm_nn3, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title('Confusion Matrix — Neural Network (Case 3)')\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e14ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision surface for NN on Case 3 (2D)\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "padding = 1\n",
    "x_min, x_max = X3['Glucose'].min() - padding, X3['Glucose'].max() + padding\n",
    "y_min, y_max = X3['BMI'].min() - padding, X3['BMI'].max() + padding\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500),\n",
    "                     np.linspace(y_min, y_max, 500))\n",
    "\n",
    "Z = nn_model3.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "cmap_background = ListedColormap(['lightblue', 'lightyellow'])\n",
    "plt.contourf(xx, yy, Z, cmap=cmap_background, alpha=0.7)\n",
    "\n",
    "# Overlay test points\n",
    "plt.scatter(X3_test['Glucose'][y3_test == 0], X3_test['BMI'][y3_test == 0],\n",
    "            c='blue', marker='^', edgecolor='k', label='No Diabetes (0)')\n",
    "plt.scatter(X3_test['Glucose'][y3_test == 1], X3_test['BMI'][y3_test == 1],\n",
    "            c='gold', marker='s', edgecolor='k', label='Diabetes (1)')\n",
    "\n",
    "plt.xlabel('Glucose'); plt.ylabel('BMI')\n",
    "plt.title('Neural Network Decision Surface — Case 3 (Glucose + BMI)')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ec045",
   "metadata": {},
   "source": [
    "**Reflection 5:**  \n",
    "Compare Decision Tree vs SVC vs NN. Which performed best on **test** data? Any surprises? Why might one model be better for this dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372eee9d",
   "metadata": {},
   "source": [
    "## Section 6. Final Thoughts & Insights\n",
    "\n",
    "- **6.1 Summary of Findings:** (include a small table of key metrics by model/case)\n",
    "- **6.2 Challenges:** (data quality, zeros→NaN, class balance, convergence, etc.)\n",
    "- **6.3 Next Steps:** (try more features, scaling for SVC/NN, logistic regression, Random Forest, hyperparameter tuning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc79106d",
   "metadata": {},
   "source": [
    "**Reflection 6:**  \n",
    "What did you learn from this project? What would you try next with more time?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
